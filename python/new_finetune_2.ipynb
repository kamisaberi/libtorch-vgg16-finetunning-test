{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-10T22:33:03.457520Z",
     "start_time": "2025-08-10T22:08:05.049961Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Use a dictionary for easy management of hyperparameters\n",
    "config = {\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"BATCH_SIZE\": 64,        # Use a larger batch size for caching and training\n",
    "    \"NUM_EPOCHS\": 10,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"DATA_DIR\": \"/home/kami/Documents/datasets/\",    # Directory to store Food101 dataset\n",
    "    \"NUM_CLASSES\": 101,      # Food101 has 101 classes\n",
    "    \"VGG16_FEATURE_SIZE\": 25088 # VGG16 output size after features and avgpool\n",
    "}\n",
    "\n",
    "print(f\"Using device: {config['DEVICE']}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 2. The Custom Caching Model ---\n",
    "class CachedFineTuneModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A model that caches activations from frozen layers to accelerate fine-tuning.\n",
    "    \"\"\"\n",
    "    def __init__(self, original_model, num_classes, num_records):\n",
    "        super().__init__()\n",
    "        # Separate the frozen part of the model\n",
    "        self.features = original_model.features\n",
    "        self.avgpool = original_model.avgpool\n",
    "\n",
    "        # Create a new trainable classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(config[\"VGG16_FEATURE_SIZE\"], 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize the cache buffer on the CPU first\n",
    "        initial_cache = torch.zeros(num_records, config[\"VGG16_FEATURE_SIZE\"])\n",
    "        # Register as a buffer: PyTorch will manage its device and state\n",
    "        self.register_buffer('frozen_data', initial_cache)\n",
    "        self.register_buffer('is_cached', torch.tensor(False))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def cache_activations(self, dataloader: DataLoader):\n",
    "        \"\"\"\n",
    "        Performs the one-time forward pass to populate the activation cache.\n",
    "        MUST be run in eval mode to ensure deterministic outputs from BatchNorm.\n",
    "        \"\"\"\n",
    "        print(\"--- Phase 1: Caching Activations ---\")\n",
    "        self.eval() # CRITICAL: Use eval mode for deterministic caching\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        start_time = time.time()\n",
    "\n",
    "        for i, (data, _) in enumerate(tqdm(dataloader, desc=\"Caching Progress\")):\n",
    "            data = data.to(device)\n",
    "            batch_size = data.shape[0]\n",
    "            start_index = i * dataloader.batch_size\n",
    "            end_index = start_index + batch_size\n",
    "\n",
    "            activations = self.avgpool(self.features(data))\n",
    "            activations = torch.flatten(activations, 1)\n",
    "            self.frozen_data[start_index:end_index] = activations.cpu() # Store on CPU\n",
    "\n",
    "        self.is_cached.fill_(True)\n",
    "        caching_time = time.time() - start_time\n",
    "        print(f\"Caching complete in {caching_time:.2f} seconds.\")\n",
    "        # Move the entire cache to the target device after population\n",
    "        self.frozen_data = self.frozen_data.to(device)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        - If cached, `x` is a tensor of indices.\n",
    "        - If not cached (e.g., during validation), `x` is an image tensor.\n",
    "        \"\"\"\n",
    "        if self.training and self.is_cached:\n",
    "            # Training phase: x is a batch of indices\n",
    "            # Retrieve cached data directly from the buffer\n",
    "            cached_batch = self.frozen_data[x]\n",
    "            return self.classifier(cached_batch)\n",
    "        else:\n",
    "            # Validation phase or pre-caching: x is a batch of images\n",
    "            # Perform the full forward pass\n",
    "            x = self.avgpool(self.features(x))\n",
    "            x = torch.flatten(x, 1)\n",
    "            return self.classifier(x)\n",
    "\n",
    "# --- 3. Data Loading ---\n",
    "# Define transforms. No random augmentations for caching/validation.\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"Loading Food101 dataset. This may take a while on the first run...\")\n",
    "# Training set for caching (split='train')\n",
    "train_dataset_caching = datasets.Food101(\n",
    "    root=config[\"DATA_DIR\"], split='train', download=True, transform=data_transforms\n",
    ")\n",
    "caching_loader = DataLoader(\n",
    "    train_dataset_caching, batch_size=config[\"BATCH_SIZE\"], shuffle=False\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "val_dataset = datasets.Food101(\n",
    "    root=config[\"DATA_DIR\"], split='test', download=True, transform=data_transforms\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"BATCH_SIZE\"], shuffle=False)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# --- 4. Model Initialization ---\n",
    "# Load pretrained VGG16 with Batch Normalization\n",
    "vgg16_bn = models.vgg16_bn(weights=models.VGG16_BN_Weights.DEFAULT)\n",
    "\n",
    "# Freeze the feature extraction layers\n",
    "for param in vgg16_bn.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Instantiate our custom model\n",
    "num_train_records = len(train_dataset_caching)\n",
    "model = CachedFineTuneModel(\n",
    "    original_model=vgg16_bn,\n",
    "    num_classes=config[\"NUM_CLASSES\"],\n",
    "    num_records=num_train_records\n",
    ").to(config[\"DEVICE\"])\n",
    "\n",
    "# --- 5. Caching and Training ---\n",
    "\n",
    "# Run the caching phase first\n",
    "model.cache_activations(caching_loader)\n",
    "\n",
    "# --- Prepare for the accelerated training phase ---\n",
    "print(\"\\n--- Phase 2: Accelerated Fine-Tuning ---\")\n",
    "# Create a new dataset that provides indices and original labels\n",
    "train_labels = [label for _, label in train_dataset_caching]\n",
    "training_dataset_indexed = TensorDataset(\n",
    "    torch.arange(num_train_records),\n",
    "    torch.tensor(train_labels)\n",
    ")\n",
    "training_loader = DataLoader(\n",
    "    training_dataset_indexed, batch_size=config[\"BATCH_SIZE\"], shuffle=True\n",
    ")\n",
    "\n",
    "# Optimizer should only see the parameters of the trainable classifier\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=config[\"LEARNING_RATE\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "total_training_time = 0\n",
    "\n",
    "for epoch in range(config[\"NUM_EPOCHS\"]):\n",
    "    epoch_start_time = time.time()\n",
    "    # --- Training Loop ---\n",
    "    model.train() # Set to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(training_loader, desc=f\"Epoch {epoch+1}/{config['NUM_EPOCHS']} [Training]\")\n",
    "    for batch_indices, batch_labels in pbar:\n",
    "        batch_indices = batch_indices.to(config[\"DEVICE\"])\n",
    "        batch_labels = batch_labels.to(config[\"DEVICE\"])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_indices) # Pass indices to the model\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    train_loss = running_loss / len(training_loader)\n",
    "\n",
    "    # --- Validation Loop ---\n",
    "    model.eval() # Set to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar_val = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config['NUM_EPOCHS']} [Validation]\")\n",
    "        for images, labels in pbar_val:\n",
    "            images = images.to(config[\"DEVICE\"])\n",
    "            labels = labels.to(config[\"DEVICE\"])\n",
    "\n",
    "            outputs = model(images) # Pass images to the model\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    total_training_time += epoch_time\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{config['NUM_EPOCHS']} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Loss: {val_loss:.4f} | \"\n",
    "        f\"Val Accuracy: {val_accuracy:.2f}% | \"\n",
    "        f\"Time: {epoch_time:.2f}s\"\n",
    "    )\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Finished Accelerated Training in {total_training_time:.2f} seconds.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "------------------------------\n",
      "Loading Food101 dataset. This may take a while on the first run...\n",
      "Dataset loaded successfully.\n",
      "--- Phase 1: Caching Activations ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching Progress: 100%|██████████| 1184/1184 [04:40<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching complete in 280.33 seconds.\n",
      "\n",
      "--- Phase 2: Accelerated Fine-Tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Training]: 100%|██████████| 1184/1184 [00:14<00:00, 79.59it/s, loss=2.7841]\n",
      "Epoch 1/10 [Validation]: 100%|██████████| 395/395 [01:50<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 2.9777 | Val Loss: 1.9860 | Val Accuracy: 50.61% | Time: 125.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Training]: 100%|██████████| 1184/1184 [00:15<00:00, 76.75it/s, loss=2.8392]\n",
      "Epoch 2/10 [Validation]: 100%|██████████| 395/395 [01:30<00:00,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 2.4156 | Val Loss: 1.9788 | Val Accuracy: 53.44% | Time: 105.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Training]: 100%|██████████| 1184/1184 [00:15<00:00, 77.69it/s, loss=1.8287]\n",
      "Epoch 3/10 [Validation]: 100%|██████████| 395/395 [01:30<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 2.1997 | Val Loss: 1.8834 | Val Accuracy: 55.48% | Time: 106.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Training]: 100%|██████████| 1184/1184 [00:14<00:00, 81.66it/s, loss=2.1120]\n",
      "Epoch 4/10 [Validation]: 100%|██████████| 395/395 [01:28<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 2.0653 | Val Loss: 1.8434 | Val Accuracy: 56.45% | Time: 102.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Training]: 100%|██████████| 1184/1184 [00:15<00:00, 77.77it/s, loss=1.6309]\n",
      "Epoch 5/10 [Validation]: 100%|██████████| 395/395 [01:32<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 1.9370 | Val Loss: 1.7803 | Val Accuracy: 57.36% | Time: 107.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Training]: 100%|██████████| 1184/1184 [00:15<00:00, 76.93it/s, loss=1.9928]\n",
      "Epoch 6/10 [Validation]: 100%|██████████| 395/395 [01:35<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 1.8728 | Val Loss: 1.7852 | Val Accuracy: 56.84% | Time: 110.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Training]: 100%|██████████| 1184/1184 [00:15<00:00, 78.89it/s, loss=1.9704]\n",
      "Epoch 7/10 [Validation]: 100%|██████████| 395/395 [01:31<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 1.7967 | Val Loss: 1.7354 | Val Accuracy: 57.74% | Time: 106.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Training]: 100%|██████████| 1184/1184 [00:14<00:00, 79.32it/s, loss=1.4379]\n",
      "Epoch 8/10 [Validation]: 100%|██████████| 395/395 [01:29<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 1.7395 | Val Loss: 1.7713 | Val Accuracy: 57.30% | Time: 104.66s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Training]: 100%|██████████| 1184/1184 [00:14<00:00, 79.49it/s, loss=2.4841]\n",
      "Epoch 9/10 [Validation]: 100%|██████████| 395/395 [01:27<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 1.6883 | Val Loss: 1.7741 | Val Accuracy: 57.55% | Time: 102.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Training]: 100%|██████████| 1184/1184 [00:15<00:00, 78.90it/s, loss=1.8750]\n",
      "Epoch 10/10 [Validation]: 100%|██████████| 395/395 [01:31<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 1.6471 | Val Loss: 1.7608 | Val Accuracy: 57.28% | Time: 106.45s\n",
      "------------------------------\n",
      "Finished Accelerated Training in 1079.10 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "251d4a3b16805aae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
